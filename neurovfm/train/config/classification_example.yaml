# Example configuration for supervised classification
# Fine-tunes frozen backbone with MIL pooling

# Infrastructure settings
infra:
  exp_root: /path/to/experiments/classification_run1
  seed: 42
  num_gpus: 2
  num_nodes: 1
  log_gpu: false
  log_every_n_steps: 50
  wandb_project: neurovfm_classification
  comment: hemorrhage_classification

# Data configuration
data:
  raw_data_dir: /path/to/raw_data
  cache_dir: /path/to/preprocessed_cache
  
  mode_mapping:
    study_001: mri
    study_002: ct
    # ... add all studies
  
  dataset:
    train:
      studies:
        - study_001
        - study_002
        # ... training studies
      params:
        random_crop: false
        augment: true  # Enable augmentation for training
        tokenize: true
        ct_window_probs: [0.7, 0.15, 0.15]
    
    val:
      studies:
        - study_003
        # ... validation studies
      params:
        random_crop: false
        augment: false
        tokenize: true
        ct_window_probs: [0.7, 0.15, 0.15]
  
  loader:
    train:
      batch_size: 4
      num_workers: 8
      shuffle: true
      drop_last: true
      use_study_sampler: true  # Study-level batching
      collate_fn:
        remove_background: true
        patch_drop_rate: 0.0
        apply_masks_internally: false
    
    val:
      batch_size: 4
      num_workers: 8
      shuffle: false
      drop_last: false
      use_study_sampler: true
      collate_fn:
        remove_background: true
        patch_drop_rate: 0.0
        apply_masks_internally: false

# System configuration
system:
  which: VisionClassificationSystem
  params:
    # Model hyperparameters
    model_hyperparams:
      # Frozen vision backbone (same as pretraining)
      vision_backbone_cf:
        which: vit_base
        params:
          token_dim: 1024
          embed_layer_cf:
            which: voxel
            params:
              patch_hw_size: 16
              patch_d_size: 4
              in_chans: 1
              embed_dim: 768
          pos_emb_cf:
            which: pe3d
            params:
              d: 30
              d_size: 128
              hw_size: 192
              concat: true
      
      # MIL pooler
      pooler_cf:
        which: abmil  # Options: abmil, addmil, avgpool
        params:
          hidden_dim: 512
          W_out: 1
          use_gating: true
          use_norm: true
      
      # Classification head
      proj_params:
        out_dim: 1  # Binary classification (use >1 for multi-class/multi-label)
        hidden_dims: [384]
      
      # Optional: predictor for intermediate predictions
      # predictor_cf: null
    
    # Loss configuration
    loss_cf:
      which: bce  # Options: bce, ce, mse, mae, rmse
      params: {}
    
    # Optimizer
    opt_cf:
      which: adamw
      params:
        lr: 1e-4
        weight_decay: 0.01
    
    # Scheduler
    schd_cf:
      which: cosine
      params:
        ipe_scale: 1.0
        warmup_epochs: 5
        min_lr: 1e-6
    
    # Enable intensity augmentations during training
    enable_aug: true

# Training configuration
training:
  trainer_params:
    max_epochs: 50
    gradient_clip_val: 1.0
    precision: bf16-mixed
  
  monitor_metric: val/auc_epoch
  monitor_mode: max
  checkpoint_every_n_epochs: 5
  
  # Load pretrained backbone
  load_backbone:
    ckpt_path: /path/to/pretraining_checkpoint.ckpt
    remove_prefix: student_encoder.  # Remove this prefix from state dict keys
  
  # Optional: resume from checkpoint
  # resume_checkpoint: /path/to/classification_checkpoint.ckpt

